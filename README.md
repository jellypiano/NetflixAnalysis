# Netflix Analysis Project with Scala & Hadoop
## Project Overview
This project focuses on analyzing a Netflix dataset using Apache Hadoop for distributed data processing and Scala as the primary programming language. By leveraging Hadoop’s scalable storage (HDFS) and MapReduce or Spark jobs written in Scala, the goal is to uncover insights such as popular genres, release year distributions, user ratings patterns, and potential content recommendations—all at a large scale.

### Features
Distributed Data Processing: Utilize Hadoop’s HDFS for storing large amounts of data, enabling parallel computation across multiple nodes.
Scala-Based Jobs: Implement data cleaning, transformation, and aggregation with Scala, running in a Hadoop ecosystem (MapReduce or Spark).
Insightful Analysis: Explore correlations in titles, genres, release dates, and user ratings to generate actionable recommendations or strategic content decisions.
Scalability & Efficiency: Process substantial data sets quickly and efficiently, thanks to Hadoop’s distributed computing model.
### Technologies & Tools
Apache Hadoop (HDFS, YARN, MapReduce)
Scala (2.12/2.13 or appropriate version)
Apache Spark (optional, if you’re using Spark for distributed processing instead of pure MapReduce)
SBT or Maven for building and managing Scala project
